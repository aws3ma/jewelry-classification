{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jewelry classification final.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPMuu6iTZMiPU6PjgxXY/U5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aws3ma/jewelry-classification/blob/main/jewelry_classification_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7OF7ba5jur5",
        "outputId": "fd4760d0-50ad-4c82-b239-bf6eb53dd35b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import cv2\n",
        "import os\n",
        "classification_folder='/content/drive/MyDrive/classification/'\n",
        "image_size = (180, 180)\n"
      ],
      "metadata": {
        "id": "X5N2soyTj42L"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cleaning images\n",
        "num_skipped = 0\n",
        "for folder_name in (\"bagues\", \"boucles\",\"bracelet\",\"collier\"):\n",
        "    folder_path = os.path.join(classification_folder+'/train', folder_name)\n",
        "    for fname in os.listdir(folder_path):\n",
        "        fpath = os.path.join(folder_path, fname)\n",
        "        try:\n",
        "            fobj = open(fpath, \"rb\")\n",
        "            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n",
        "        finally:\n",
        "            fobj.close()\n",
        "\n",
        "        if not is_jfif:\n",
        "            num_skipped += 1\n",
        "            # Delete corrupted image\n",
        "            os.remove(fpath)\n",
        "\n",
        "print(\"Deleted %d images\" % num_skipped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V6_CDAFkmbI",
        "outputId": "d510614f-f2ea-4b4d-f91c-312ccba3ef8f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted 0 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = pathlib.Path(classification_folder+'train/')\n",
        "jewelry_images_dict={\n",
        "    'bagues':list(data_dir.glob('bagues/*')),\n",
        "    'boucle':list(data_dir.glob('boucles/*')),\n",
        "    'bracelet':list(data_dir.glob('bracelet/*')),\n",
        "    'collier':list(data_dir.glob('collier/*'))\n",
        "}\n",
        "jewelry_labels_dict={\n",
        "    'bagues':0,\n",
        "    'boucle':1,\n",
        "    'bracelet':2,\n",
        "    'collier':3\n",
        "}\n",
        "x,y=[],[]\n",
        "for jewelry_name, images in jewelry_images_dict.items():\n",
        "  for image in images:\n",
        "    img = cv2.imread(str(image))\n",
        "    resized_img = cv2.resize(img,(180,180))\n",
        "    x.append(resized_img)\n",
        "    y.append(jewelry_labels_dict[jewelry_name])"
      ],
      "metadata": {
        "id": "74XfpHHPkFM9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "x_train, x_test, y_train, y_test=train_test_split(x,y,random_state=0)\n",
        "x_train_scaled = x_train/255\n",
        "x_test_scaled = x_test/255"
      ],
      "metadata": {
        "id": "YUpcmX8ckF2H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_aug= keras.Sequential([\n",
        "                            layers.experimental.preprocessing.RandomFlip(\"horizontal\",input_shape=(180,180,3)),\n",
        "                            layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "                            layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "                            layers.experimental.preprocessing.RandomContrast([0.9,1.1])\n",
        "                            \n",
        "])"
      ],
      "metadata": {
        "id": "BxGSe3fpkInv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=keras.Sequential([\n",
        "                        data_aug,\n",
        "                        layers.Conv2D(16, 3, padding=\"same\", activation='relu'),\n",
        "                        layers.MaxPooling2D(),\n",
        "                        layers.Conv2D(32,3,padding=\"same\",activation='relu'),\n",
        "                        layers.MaxPooling2D(),\n",
        "                        layers.Conv2D(64,3,padding=\"same\",activation='relu'),\n",
        "                        layers.MaxPooling2D(),\n",
        "                        layers.Dropout(0.2),\n",
        "                        layers.Flatten(),\n",
        "                        layers.Dense(128, activation=\"relu\"),\n",
        "                        layers.Dense(4, activation='softmax'),\n",
        "])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train_scaled, y_train,epochs=100)\n",
        "model.save(classification_folder+\"checkpoints/final/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoZZ3UrRkOeX",
        "outputId": "47e16f1c-8518-4661-ea32-b2727c485be9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 24s 1s/step - loss: 1.5531 - accuracy: 0.3015\n",
            "Epoch 2/100\n",
            "21/21 [==============================] - 32s 2s/step - loss: 1.3161 - accuracy: 0.3682\n",
            "Epoch 3/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 1.1564 - accuracy: 0.5061\n",
            "Epoch 4/100\n",
            "21/21 [==============================] - 24s 1s/step - loss: 1.1727 - accuracy: 0.4985\n",
            "Epoch 5/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 1.0306 - accuracy: 0.5985\n",
            "Epoch 6/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.9501 - accuracy: 0.6439\n",
            "Epoch 7/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.9480 - accuracy: 0.5924\n",
            "Epoch 8/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 1.1685 - accuracy: 0.5788\n",
            "Epoch 9/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 1.0473 - accuracy: 0.6076\n",
            "Epoch 10/100\n",
            "21/21 [==============================] - 23s 1s/step - loss: 0.9723 - accuracy: 0.6136\n",
            "Epoch 11/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.9641 - accuracy: 0.5833\n",
            "Epoch 12/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.9661 - accuracy: 0.6106\n",
            "Epoch 13/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.9067 - accuracy: 0.6242\n",
            "Epoch 14/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.8928 - accuracy: 0.6348\n",
            "Epoch 15/100\n",
            "21/21 [==============================] - 24s 1s/step - loss: 0.7163 - accuracy: 0.7258\n",
            "Epoch 16/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.8076 - accuracy: 0.6894\n",
            "Epoch 17/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.7900 - accuracy: 0.6864\n",
            "Epoch 18/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.6250 - accuracy: 0.7561\n",
            "Epoch 19/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.8095 - accuracy: 0.6864\n",
            "Epoch 20/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.6721 - accuracy: 0.7485\n",
            "Epoch 21/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.6811 - accuracy: 0.7515\n",
            "Epoch 22/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.5711 - accuracy: 0.7727\n",
            "Epoch 23/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.5455 - accuracy: 0.8030\n",
            "Epoch 24/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.5603 - accuracy: 0.7939\n",
            "Epoch 25/100\n",
            "21/21 [==============================] - 24s 1s/step - loss: 0.5734 - accuracy: 0.7606\n",
            "Epoch 26/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.7146 - accuracy: 0.7197\n",
            "Epoch 27/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.5947 - accuracy: 0.7712\n",
            "Epoch 28/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.5100 - accuracy: 0.8106\n",
            "Epoch 29/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.4816 - accuracy: 0.8076\n",
            "Epoch 30/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.5208 - accuracy: 0.8212\n",
            "Epoch 31/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.4995 - accuracy: 0.8030\n",
            "Epoch 32/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.5961 - accuracy: 0.7833\n",
            "Epoch 33/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.4310 - accuracy: 0.8212\n",
            "Epoch 34/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.4419 - accuracy: 0.8273\n",
            "Epoch 35/100\n",
            "21/21 [==============================] - 24s 1s/step - loss: 0.4130 - accuracy: 0.8500\n",
            "Epoch 36/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.4007 - accuracy: 0.8439\n",
            "Epoch 37/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.4821 - accuracy: 0.8333\n",
            "Epoch 38/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.3664 - accuracy: 0.8606\n",
            "Epoch 39/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.3324 - accuracy: 0.8758\n",
            "Epoch 40/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.4308 - accuracy: 0.8227\n",
            "Epoch 41/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.3016 - accuracy: 0.8864\n",
            "Epoch 42/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.3520 - accuracy: 0.8591\n",
            "Epoch 43/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.2872 - accuracy: 0.9015\n",
            "Epoch 44/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.2757 - accuracy: 0.8985\n",
            "Epoch 45/100\n",
            "21/21 [==============================] - 24s 1s/step - loss: 0.3197 - accuracy: 0.8939\n",
            "Epoch 46/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.2915 - accuracy: 0.9015\n",
            "Epoch 47/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.2402 - accuracy: 0.9091\n",
            "Epoch 48/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.3980 - accuracy: 0.8515\n",
            "Epoch 49/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.4911 - accuracy: 0.8000\n",
            "Epoch 50/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.3699 - accuracy: 0.8606\n",
            "Epoch 51/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.4432 - accuracy: 0.8379\n",
            "Epoch 52/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.3333 - accuracy: 0.8833\n",
            "Epoch 53/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.2056 - accuracy: 0.9288\n",
            "Epoch 54/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.2361 - accuracy: 0.9121\n",
            "Epoch 55/100\n",
            "21/21 [==============================] - 23s 1s/step - loss: 0.2532 - accuracy: 0.9136\n",
            "Epoch 56/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.2654 - accuracy: 0.8803\n",
            "Epoch 57/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.2723 - accuracy: 0.9061\n",
            "Epoch 58/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.2790 - accuracy: 0.8909\n",
            "Epoch 59/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.3084 - accuracy: 0.8864\n",
            "Epoch 60/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.2528 - accuracy: 0.9106\n",
            "Epoch 61/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.3186 - accuracy: 0.8955\n",
            "Epoch 62/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.2893 - accuracy: 0.8970\n",
            "Epoch 63/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.2973 - accuracy: 0.8788\n",
            "Epoch 64/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.2335 - accuracy: 0.9076\n",
            "Epoch 65/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.2480 - accuracy: 0.8955\n",
            "Epoch 66/100\n",
            "21/21 [==============================] - 24s 1s/step - loss: 0.3182 - accuracy: 0.8818\n",
            "Epoch 67/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.3559 - accuracy: 0.8682\n",
            "Epoch 68/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.3742 - accuracy: 0.8621\n",
            "Epoch 69/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.3752 - accuracy: 0.8606\n",
            "Epoch 70/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.3260 - accuracy: 0.8939\n",
            "Epoch 71/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.2682 - accuracy: 0.9136\n",
            "Epoch 72/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.1988 - accuracy: 0.9152\n",
            "Epoch 73/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.1401 - accuracy: 0.9576\n",
            "Epoch 74/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.1695 - accuracy: 0.9470\n",
            "Epoch 75/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.1585 - accuracy: 0.9288\n",
            "Epoch 76/100\n",
            "21/21 [==============================] - 23s 1s/step - loss: 0.1524 - accuracy: 0.9470\n",
            "Epoch 77/100\n",
            "21/21 [==============================] - 23s 1s/step - loss: 0.2194 - accuracy: 0.9167\n",
            "Epoch 78/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.2003 - accuracy: 0.9394\n",
            "Epoch 79/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.1553 - accuracy: 0.9409\n",
            "Epoch 80/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.1521 - accuracy: 0.9576\n",
            "Epoch 81/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.2144 - accuracy: 0.9197\n",
            "Epoch 82/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.1194 - accuracy: 0.9621\n",
            "Epoch 83/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.1548 - accuracy: 0.9424\n",
            "Epoch 84/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.1477 - accuracy: 0.9439\n",
            "Epoch 85/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.0837 - accuracy: 0.9697\n",
            "Epoch 86/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.1922 - accuracy: 0.9227\n",
            "Epoch 87/100\n",
            "21/21 [==============================] - 24s 1s/step - loss: 0.2039 - accuracy: 0.9333\n",
            "Epoch 88/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.1607 - accuracy: 0.9500\n",
            "Epoch 89/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.0990 - accuracy: 0.9636\n",
            "Epoch 90/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.1500 - accuracy: 0.9394\n",
            "Epoch 91/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.1497 - accuracy: 0.9455\n",
            "Epoch 92/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.1420 - accuracy: 0.9576\n",
            "Epoch 93/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.1051 - accuracy: 0.9636\n",
            "Epoch 94/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.1377 - accuracy: 0.9545\n",
            "Epoch 95/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.1556 - accuracy: 0.9333\n",
            "Epoch 96/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.1192 - accuracy: 0.9591\n",
            "Epoch 97/100\n",
            "21/21 [==============================] - 24s 1s/step - loss: 0.1507 - accuracy: 0.9439\n",
            "Epoch 98/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.0834 - accuracy: 0.9697\n",
            "Epoch 99/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.1333 - accuracy: 0.9470\n",
            "Epoch 100/100\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.1172 - accuracy: 0.9606\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/classification/checkpoints/final/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test_scaled,y_test)\n",
        "model.save(classification_folder+\"checkpoints/9/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AspkcgnkULI",
        "outputId": "92a87494-5e6e-445b-b690-5b9936861cb4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 2s 267ms/step - loss: 0.4217 - accuracy: 0.9140\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/classification/checkpoints/9/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_bague=0\n",
        "nb_boucles=0\n",
        "nb_bracelet=0\n",
        "nb_collier=0\n",
        "test_path=classification_folder+'test/NECKLACE/'\n",
        "for i in os.listdir(test_path):\n",
        "  img = keras.preprocessing.image.load_img(\n",
        "      test_path+i, \n",
        "      target_size=image_size,\n",
        "  )\n",
        "  plt.imshow(img)\n",
        "  plt.show()\n",
        "  img_array = keras.preprocessing.image.img_to_array(img)\n",
        "  img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
        "\n",
        "  predictions = model.predict(img_array)\n",
        "  l=predictions.tolist()[0]\n",
        "  print(l)\n",
        "  if l.index(max(l)) == 0:\n",
        "    nb_bague+=1\n",
        "    print(\"bague\")\n",
        "  if l.index(max(l)) == 1:\n",
        "    nb_boucles+=1\n",
        "    print(\"boucle\")\n",
        "  if l.index(max(l)) == 2:\n",
        "    nb_bracelet+=1\n",
        "    print(\"bracelet\")\n",
        "  if l.index(max(l)) == 3:\n",
        "    nb_collier+=1\n",
        "    print(\"collier\")\n",
        "  # print(f'{100*l[0]}% bagues \\n{100*l[1]}% boucles \\n{100*l[2]}% bracelet \\n{100*l[3]}% collier')\n",
        "print(f\"Bagues : {nb_bague}\\nBoucles : {nb_boucles}\\nBracelet : {nb_bracelet}\\nCollier : {nb_collier}\")"
      ],
      "metadata": {
        "id": "PN4dOfPtkgSv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}